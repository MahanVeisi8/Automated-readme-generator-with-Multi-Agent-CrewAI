# üöÄ Automated README Generator using Multi-Agent CrewAI ü§ñ
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1LQAnuuqdHNWhfrBc6KH03WDKyTlc4AeR?usp=sharing)
![Python](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9-blue)
![Status](https://img.shields.io/badge/status-active-green)

Creating the perfect README has always been a crucial part of any project. It's the first impression developers and collaborators get from your repository. However, crafting a well-structured, detailed, and visually appealing README takes time and effort. That's why I decided to automate this process using **CrewAI** and **LLaMA 3 - 70B**.

The core of this system revolves around **three collaborative crews**:
1. **Style Crew**: This crew analyzes a sample README that reflects my preferred style, such as the one from [RL Practices - DQN](https://github.com/MahanVeisi8/RL_practices/tree/main/Cartpole/1%20-%20DQN).
2. **Code Crew**: This crew digs deep into the project code, like in [Readahead Optimization using ML Models](https://github.com/MahanVeisi8/Readahead-Optimization-Using-ML-Models), extracting key information to ensure the README is accurate and thorough.
3. **README Generator Crew**: Combining insights from the Style and Code Crews, this team writes the final README, complete with structure, details, and creative touches.

The project overview below demonstrates how the three crews work together, processing inputs like sample READMEs and source code, powered by **CrewAI** and the powerful **LLaMA 3 - 70B** model.

![CrewAI Project Overview](asset/model.jpg)

With this setup, I‚Äôve automated the task of producing top-quality, personalized READMEs that align perfectly with my style preferences‚Äîmaking the process faster, consistent, and fun!



## üìã Table of Contents

- [Introduction](#introduction)
- [Installation and Setup](#installation-and-setup)
- [How CrewAI Works](#how-crewAI-works)
  - [Analyzing Style](#analyzing-style)
  - [Code Structure Review](#code-structure-review)
  - [Generating README](#generating-readme)
- [Sample README Output](#sample-readme-output)
- [Results](#results)
- [Conclusion](#conclusion)

---

## üìñ Introduction

This project demonstrates how **Multi-Agent CrewAI** automates the generation of `README.md` files by analyzing the project structure, identifying desired styles, and reviewing the code for essential technical details. The result is a beautifully formatted and professionally structured README.

---

## üõ† Installation and Setup

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-repo/automated-readme-generator.git
   ```
2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
3. **Set Up API Keys**:
   Set up your **GROQ API Key** and other environment variables:
   ```bash
   export GROQ_API_KEY=your-key-here
   ```

---

## ü§ñ How CrewAI Works

The automated README generator employs **CrewAI** agents, each with specialized roles:

### 1. Analyzing Style üìù

The **Style Analyzer Agent** learns the desired structure and style from past READMEs (e.g., [RL Practices](https://github.com/MahanVeisi8/RL_practices/tree/main/Cartpole/1%20-%20DQN)). This allows the generated README to align with specific formatting and tone preferences.

### 2. Code Structure Review üíª

The **Code Review Agent** reads through the repository's code, especially projects like [Readahead Optimization using ML Models](https://github.com/MahanVeisi8/Readahead-Optimization-Using-ML-Models), to extract the essential technical details for inclusion in the README.

### 3. Generating README üìÑ

The **README Generator Agent** merges the findings from the style and code analysis, formatting the final README. It ensures the documentation is coherent, professional, and‚Äîlet's not forget‚Äîfun with emojis and creative elements!

---

## üìÑ Sample README Output

Here‚Äôs an example of the README generated by CrewAI:

### Final README Content: 

```md
Final README Content:  Here is the rewritten README file:

# Optimizing Readahead Feature of Linux Page Cache using Machine Learning üìäüíª

This repository provides a comprehensive implementation of optimizing the Readahead feature of the Linux Page Cache under varying workloads using machine learning techniques.

## Setup üíª

### Prerequisites

* Python version: 3.x
* Libraries: scikit-learn, numpy, pandas, etc.
* Installation instructions: `pip install -r requirements.txt`

### Environment Setup

* Create a virtual environment: `python -m venv env`
* Activate the virtual environment: `source env/bin/activate`

## Implementing Machine Learning Components ü§ñ

### Feature Importance Analysis

* Brief description: Random Forest Classifier was used to analyze feature importance, and non-important features were removed.
* Code snippet or example: [Insert code snippet]
* Explanation of the component's functionality: This component is used to identify the most important features that affect the Readahead size.

### Dimensionality Reduction

* Brief description: T-SNE was used to visualize the data in 2D.
* Code snippet or example: [Insert code snippet]
* Explanation of the component's functionality: This component is used to reduce the dimensionality of the data and visualize it in 2D.

### Model Training üöÄ

* **Neural Network**
	+ Brief description: MLPClassifier was used with hidden layers of 64 and 32 neurons.
	+ Code snippet or example: [Insert code snippet]
	+ Explanation of the component's functionality: This component is used to train a neural network model to classify workload types and suggest optimal Readahead sizes.
* **Decision Tree**
	+ Brief description: DecisionTreeClassifier was used.
	+ Code snippet or example: [Insert code snippet]
	+ Explanation of the component's functionality: This component is used to train a decision tree model to classify workload types and suggest optimal Readahead sizes.
* **Random Forest**
	+ Brief description: RandomForestClassifier was used with 100 estimators.
	+ Code snippet or example: [Insert code snippet]
	+ Explanation of the component's functionality: This component is used to train a random forest model to classify workload types and suggest optimal Readahead sizes.

## Results and Performance Analysis üìä

### Model Comparison

| Model            | Accuracy  | Notes                                       |
|------------------|-----------|---------------------------------------------|
| Decision Tree    | 100.00%   | Simple, interpretable, perfect accuracy     |
| Neural Network   | 99.85%    | High accuracy, complex model with slight variability in precision |
| Random Forest    | 100.00%   | Combines multiple trees for perfect accuracy and generalization |

### Performance Comparison

* The results show that both the Decision Tree and Random Forest models achieved perfect accuracy, while the Neural Network model had a slightly lower accuracy.

## Summary üìö

This project provides a comprehensive implementation of optimizing the Readahead feature of the Linux Page Cache under varying workloads using machine learning techniques, demonstrating the effectiveness of machine learning techniques in optimizing the Readahead feature under varying workloads. The results show that the Random Forest model stands out for its combination of accuracy and interpretability, making it a strong candidate for real-time systems that require dynamic adjustment of Readahead sizes based on current workloads.
Final README saved to: FINAL_README.md
```

*For the complete output, check out the file [FINAL_README.md](FINAL_README.md)*

---

## üìä Results

This project demonstrated that AI-based automation tools, such as **CrewAI**, can effectively generate high-quality documentation with minimal manual intervention. The generated README files are not only accurate but also engaging, visually appealing, and professional.

---

## üîö Conclusion

With **CrewAI**, writing complex, structured documentation becomes fully automated, saving time and maintaining high-quality standards. This system is perfect for projects like [Readahead Optimization](https://github.com/MahanVeisi8/Readahead-Optimization-Using-ML-Models), where extensive technical details need to be documented alongside a preferred style. 
